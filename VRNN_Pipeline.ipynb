{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edb0f6d-943c-48d5-bd3c-10de317eff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 19:11:48.939584: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-10 19:11:48.985943: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 19:11:49.678127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os   \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import imageio\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pickle\n",
    "import gc\n",
    "import pickle\n",
    "import yaml\n",
    "from torch import nn\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import os, sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8449e097-48bd-4feb-bd39-68ed00f8b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.FOMM.Source_Model.logger import Logger, Visualizer\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.FOMM.Source_Model.sync_batchnorm import DataParallelWithCallback\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.FOMM.Source_Model.modules.RNN_prediction_module import PredictionModule\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.FOMM.Source_Model.augmentation import SelectRandomFrames, SelectFirstFrames_two, VideoToTensor\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.FOMM.Source_Model.frames_dataset import FramesDataset\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.PREDICTOR.Source_Model.VRNN import build_vrnn, get_config\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.PREDICTOR.Source_Model.VRNN_prediction import VRNN_predict\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.PREDICTOR.Source_Model.prediction_toplevel import KPDataset,get_data_from_dataloader_60\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.FOMM.Source_Model.modules.generator import OcclusionAwareGenerator,calculate_frechet_distance,compute_fvd\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.FOMM.Source_Model.modules.keypoint_detector import KPDetector\n",
    "from Motion_Transfer_Keypoints_Prediction.Keypoints_Prediction.Training_Prediction.FOMM.Source_Model.logger import Logger, Visualizer, Visualizer_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f96c3-742f-470f-add2-e23655ad2eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kp_train_3883_vox.pkl\", \"rb\") as f:\n",
    "    kp_time_series = pickle.load(f)\n",
    "len(kp_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5d39bd-36d2-4c0e-8280-80a3f339cc15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kp_time_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# convert list of keypoints to dictionary: \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mkp_time_series\u001b[49m)):\n\u001b[1;32m      3\u001b[0m     kp_time_series[video_idx] \u001b[38;5;241m=\u001b[39m kp_time_series[video_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m kp_dict_init \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kp_time_series' is not defined"
     ]
    }
   ],
   "source": [
    "# convert list of keypoints to dictionary: \n",
    "for video_idx in range(len(kp_time_series)):\n",
    "    kp_time_series[video_idx] = kp_time_series[video_idx]['kp']\n",
    "\n",
    "kp_dict_init = []\n",
    "for video_idx in range(len(kp_time_series)): # \n",
    "    init_mean = []\n",
    "    init_jacobian = []\n",
    "    for frame_idx in range(len(kp_time_series[video_idx])):\n",
    "        kp_mean = kp_time_series[video_idx][frame_idx]['value'].reshape(1,10,2)\n",
    "        kp_mean = torch.tensor(kp_mean)\n",
    "        kp_jacobian = kp_time_series[video_idx][frame_idx]['jacobian'].reshape(1,10,2,2)\n",
    "        kp_jacobian = torch.tensor(kp_jacobian)\n",
    "\n",
    "        init_mean.append(kp_mean)\n",
    "        init_jacobian.append(kp_jacobian)\n",
    "\n",
    "    init_mean = torch.cat(init_mean)\n",
    "    init_jacobian = torch.cat(init_jacobian)\n",
    "\n",
    "    init_mean = torch.reshape(init_mean,(1,init_mean.shape[0],init_mean.shape[1],init_mean.shape[2]))\n",
    "    init_jacobian = torch.reshape(init_jacobian,(1,init_jacobian.shape[0],10,2,2))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # add tensor to cuda\n",
    "        init_mean = init_mean.to('cuda:0')\n",
    "        init_jacobian = init_jacobian.to('cuda:0')\n",
    "\n",
    "    kp_dict_both = {\"value\":init_mean,\"jacobian\":init_jacobian}\n",
    "    kp_dict_init.append(kp_dict_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d83c6-c6ff-4f2f-b975-8adf7c76c9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
